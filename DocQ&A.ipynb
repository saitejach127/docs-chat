{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f7b50cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import ast  # for converting embeddings saved as strings back to arrays\n",
    "import openai  # for calling the OpenAI API\n",
    "import pandas as pd  # for storing text and embeddings data\n",
    "import tiktoken  # for counting tokens\n",
    "from scipy import spatial  # for calculating vector similarities for search\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = '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'\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# models\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "GPT_MODEL = \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09a33e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download pre-chunked text and pre-computed embeddings\n",
    "# this file is ~200 MB, so may take a minute depending on your connection speed\n",
    "embeddings_path = \"csm_nltk.csv\"\n",
    "\n",
    "df = pd.read_csv(embeddings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6813eeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert embeddings from CSV str type back to list type\n",
    "df['embedding'] = df['embedding'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e57cf546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Utah Customer Service \\nManagement\\nLast updat...</td>\n",
       "      <td>[-0.01225913967937231, -0.021588172763586044, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Some examples and graphics depicted herein are...</td>\n",
       "      <td>[-0.018668705597519875, -0.010630969889461994,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Table of Contents\\nCustomer Service Management...</td>\n",
       "      <td>[0.02603786624968052, -0.011726273223757744, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ServiceNow, the ServiceNow logo, Now, and othe...</td>\n",
       "      <td>[-0.011318285949528217, -0.022291267290711403,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Customer Service Management\\nResolve complex i...</td>\n",
       "      <td>[-0.017990540713071823, -0.007459492422640324,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Utah Customer Service \\nManagement\\nLast updat...   \n",
       "1  Some examples and graphics depicted herein are...   \n",
       "2  Table of Contents\\nCustomer Service Management...   \n",
       "3  ServiceNow, the ServiceNow logo, Now, and othe...   \n",
       "4  Customer Service Management\\nResolve complex i...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.01225913967937231, -0.021588172763586044, ...  \n",
       "1  [-0.018668705597519875, -0.010630969889461994,...  \n",
       "2  [0.02603786624968052, -0.011726273223757744, 0...  \n",
       "3  [-0.011318285949528217, -0.022291267290711403,...  \n",
       "4  [-0.017990540713071823, -0.007459492422640324,...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the dataframe has two columns: \"text\" and \"embedding\"\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c88fb99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search function\n",
    "def strings_ranked_by_relatedness(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    relatedness_fn=lambda x, y: 1 - spatial.distance.cosine(x, y),\n",
    "    top_n: int = 100\n",
    ") -> tuple[list[str], list[float]]:\n",
    "    \"\"\"Returns a list of strings and relatednesses, sorted from most related to least.\"\"\"\n",
    "    query_embedding_response = openai.Embedding.create(\n",
    "        model=EMBEDDING_MODEL,\n",
    "        input=query,\n",
    "    )\n",
    "    query_embedding = query_embedding_response[\"data\"][0][\"embedding\"]\n",
    "    strings_and_relatednesses = [\n",
    "        (row[\"text\"], relatedness_fn(query_embedding, row[\"embedding\"]))\n",
    "        for i, row in df.iterrows()\n",
    "    ]\n",
    "    strings_and_relatednesses.sort(key=lambda x: x[1], reverse=True)\n",
    "    strings, relatednesses = zip(*strings_and_relatednesses)\n",
    "    return strings[:top_n], relatednesses[:top_n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "669eeb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens(text: str, model: str = GPT_MODEL) -> int:\n",
    "    \"\"\"Return the number of tokens in a string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "\n",
    "def query_message(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    model: str,\n",
    "    token_budget: int\n",
    ") -> str:\n",
    "    \"\"\"Return a message for GPT, with relevant source texts pulled from a dataframe.\"\"\"\n",
    "    strings, relatednesses = strings_ranked_by_relatedness(query, df)\n",
    "    introduction = 'Use the below ServiceNow Customer Service Management Documentation to answer the subsequent question. If the answer cannot be found in the article, write \"I could not find an answer.\"'\n",
    "    question = f\"\\n\\nQuestion: {query}\"\n",
    "    message = introduction\n",
    "    for string in strings:\n",
    "        next_article = f'\\n\\n ServiceNow Doc :\\n\"\"\"\\n{string}\\n\"\"\"'\n",
    "        if (\n",
    "            num_tokens(message + next_article + question, model=model)\n",
    "            > token_budget\n",
    "        ):\n",
    "            break\n",
    "        else:\n",
    "            message += next_article\n",
    "    return message + question\n",
    "\n",
    "\n",
    "def ask(\n",
    "    query: str,\n",
    "    df: pd.DataFrame = df,\n",
    "    model: str = GPT_MODEL,\n",
    "    token_budget: int = 4096 - 500,\n",
    "    print_message: bool = False,\n",
    ") -> str:\n",
    "    \"\"\"Answers a query using GPT and a dataframe of relevant texts and embeddings.\"\"\"\n",
    "    message = query_message(query, df, model=model, token_budget=token_budget)\n",
    "    if print_message:\n",
    "        print(message)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You answer questions about Customer Service Management, ServiceNow.\"},\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    response_message = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    return response_message\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4723b88c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Omnichannel refers to the ability to provide support to customers through multiple channels such as chat, email, phone, and messaging apps, and to ensure a seamless experience across all channels. ServiceNow offers Omnichannel Callback for Customer Service Management, which provides an option for customer service agents to call customers back when the wait time for agents is long or agents are unavailable.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask('what is ominichannel?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55071fda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Omnichannel Callback for Customer Service Management application requires the Omnichannel Callback for Customer Service Management application (com.sn_omnichannel_callback) to be installed.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask('what plugin is needed to install ominichannel?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "316bf0fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The role required for creating, viewing, updating, and deleting guidances is \"sn_gd_guidance.guidance_manager\". The role required for viewing guidances is \"sn_gd_guidance.guidance_user\". Both roles are automatically given to customer service agents and managers.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask('what are roles required for guidance?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674af152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
